{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.support_prep import *\n",
    "from src.support_models import *    \n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../datos/clean.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>...</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>PerformanceRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>Other</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>No</td>\n",
       "      <td>Non-Travel</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel              Department  DistanceFromHome  \\\n",
       "0   51        No      Travel_Rarely                   Sales                 6   \n",
       "1   31       Yes  Travel_Frequently  Research & Development                10   \n",
       "2   32        No  Travel_Frequently  Research & Development                17   \n",
       "3   38        No         Non-Travel  Research & Development                 2   \n",
       "4   32        No      Travel_Rarely  Research & Development                10   \n",
       "\n",
       "  Education EducationField  EmployeeID  Gender JobLevel  ...  \\\n",
       "0         2  Life Sciences           1  Female        1  ...   \n",
       "1         1  Life Sciences           2  Female        1  ...   \n",
       "2         4          Other           3    Male        4  ...   \n",
       "3         5  Life Sciences           4    Male        3  ...   \n",
       "4         1        Medical           5    Male        1  ...   \n",
       "\n",
       "  TotalWorkingYears TrainingTimesLastYear  YearsAtCompany  \\\n",
       "0                 1                     6               1   \n",
       "1                 6                     3               5   \n",
       "2                 5                     2               5   \n",
       "3                13                     5               8   \n",
       "4                 9                     2               6   \n",
       "\n",
       "   YearsSinceLastPromotion  YearsWithCurrManager EnvironmentSatisfaction  \\\n",
       "0                        0                     0                     3.0   \n",
       "1                        1                     4                     3.0   \n",
       "2                        0                     3                     2.0   \n",
       "3                        7                     5                     4.0   \n",
       "4                        0                     4                     4.0   \n",
       "\n",
       "   JobSatisfaction  WorkLifeBalance  JobInvolvement  PerformanceRating  \n",
       "0                4                2               3                  3  \n",
       "1                2                4               2                  4  \n",
       "2                2                1               3                  3  \n",
       "3                4                3               2                  3  \n",
       "4                1                3               3                  3  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar el encoding, vamos a necesitar convertir nuestra variable respuesta en binario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Attrition\"] = df[\"Attrition\"].map({\"No\":0, \"Yes\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora separamos nuestras variables numéricas de las categóricas, además de que para el preprocesamiento no querremos tocar la variable respuesta, y nos quitamos también el EmployeeID, ya que es esencialmente un índice que no aporta información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(\"O\").columns\n",
    "num_cols = df.select_dtypes(\"number\").columns.drop([\"Attrition\", \"EmployeeID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"EmployeeID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con una función del src podemos obtener aquellas categorías que sí presentan un orden, es decir, las proporciones de sus matrices de contingencia no coinciden con las observaciones esperadas, por lo que hay categorías con mayor relevancia que otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_diff = detectar_orden_cat(df = df, lista_cat=cat_cols,var_respuesta=\"Attrition\", show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BusinessTravel',\n",
       " 'Department',\n",
       " 'EducationField',\n",
       " 'JobRole',\n",
       " 'MaritalStatus',\n",
       " 'EnvironmentSatisfaction',\n",
       " 'JobSatisfaction',\n",
       " 'WorkLifeBalance',\n",
       " 'JobInvolvement']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_no_diff = cat_cols.drop(cat_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Education', 'Gender', 'JobLevel', 'StockOptionLevel',\n",
       "       'PerformanceRating'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_no_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que las únicas sin orden específico son el nivel educativo, el género, el nivel del puesto dentro de la empresa, las opciones de acciones y la valoración de desempeño.\n",
    "\n",
    "Vamos a hacer un target encoding para las categorías con diferencias y un onehot encoding con las categorías sin diferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target, target = encode_target(data = df, columns = cat_diff, response_var=\"Attrition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oh, onehot = encode_onehot(df, columns = cat_no_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df[\"Attrition\"], df_target.drop(columns=cat_no_diff), df_oh], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos los objetos generados en pkl para poder reutilizar los encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/onehot.pkl', 'wb') as file:\n",
    "    pickle.dump(onehot, file)\n",
    "with open('../models/target.pkl', 'wb') as file:\n",
    "    pickle.dump(target, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realizaremos una estandarización para nuestras variables, para que nuestro modelo no esté sesgado por ciertas variables que pudieran tener escalas mayores a otras, como el salario sobre los años trabajados. \n",
    "\n",
    "Se escoge minmax, ya que por una parte tenemos pocos outliers univariantes y por otra parte, al ser nuestra variable respuesta binaria, el target encoder nos genera valores entre 0 y 1 (representan la probabilidad de Attrition según las características de cada categoría), y el onehot también nos limita a 0 y 1, por lo que la escala sería adecuada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled, scaler = scale_data(data = df, columns=df.columns.drop(df_oh.columns).drop(\"Attrition\"), method = \"minmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df_scaled.columns] = df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También guardamos este objeto en un pkl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último vamos a encontrar y tratar los outliers en nuestros registros. Seguiremos una estrategia de dos pasos. De primeras buscaremos aquellos outliers más específicos, que podrían representar valores erróneos o muy atípicos. Para ello usaremos una estrategia de Isolation Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:20<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "df_outliers_ifo, ifo = find_outliers(data = df.drop(columns = \"Attrition\"), columns = df.drop(columns = \"Attrition\").columns, method = \"ifo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020861678004535148"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outliers_ifo.shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que encontramos una proporción pequeña de outliers, decidimos eliminar estos registros, ya que podrían generar ruido posteriormente en el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df_outliers_ifo.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que no tenemos valores muy atípicos, identificaremos aquellos outliers más agrupados, que podrían corresponder a un grupo de registros con características similares, pero que difieren un poco del ámbito general de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:02<00:00, 12.50it/s]\n"
     ]
    }
   ],
   "source": [
    "df_outliers_lof, lof = find_outliers(data = df.drop(columns = \"Attrition\"), columns = df.drop(columns = \"Attrition\").columns, method = \"lof\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03890690134321445"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outliers_lof.shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estos valores, convertiremos las numéricas en nulos y los imputaremos, de tal forma de que estos outliers no sean tan extremos. Para ello usaremos un random forest. Aunque este proceso sea más lento que otros, en general da mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df_outliers_lof.index, num_cols] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (4318, 38)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 10.30\n",
      "[IterativeImputer] Change: 1.0631141134959474, scaled tolerance: 0.0010000000000000002 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 20.99\n",
      "[IterativeImputer] Change: 0.806595987052009, scaled tolerance: 0.0010000000000000002 \n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 32.13\n",
      "[IterativeImputer] Change: 0.6525629898088778, scaled tolerance: 0.0010000000000000002 \n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 44.06\n",
      "[IterativeImputer] Change: 0.5354396984702255, scaled tolerance: 0.0010000000000000002 \n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 56.84\n",
      "[IterativeImputer] Change: 0.6115120961496764, scaled tolerance: 0.0010000000000000002 \n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 71.12\n",
      "[IterativeImputer] Change: 0.765920525398153, scaled tolerance: 0.0010000000000000002 \n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 86.82\n",
      "[IterativeImputer] Change: 0.5270937766891901, scaled tolerance: 0.0010000000000000002 \n",
      "[IterativeImputer] Ending imputation round 8/10, elapsed time 104.30\n",
      "[IterativeImputer] Change: 0.6291286513025434, scaled tolerance: 0.0010000000000000002 \n",
      "[IterativeImputer] Ending imputation round 9/10, elapsed time 123.92\n",
      "[IterativeImputer] Change: 0.5384291765679414, scaled tolerance: 0.0010000000000000002 \n",
      "[IterativeImputer] Ending imputation round 10/10, elapsed time 145.37\n",
      "[IterativeImputer] Change: 0.6107105530995975, scaled tolerance: 0.0010000000000000002 \n"
     ]
    }
   ],
   "source": [
    "df_out_impute, out_imputer = impute_nulls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_out_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"../datos/prepped.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
